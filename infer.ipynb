{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb4kc0YfCjG7ooxls2oV6g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeslieZhoa/HeadSwap/blob/main/infer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZfYoKXr6rxi",
        "outputId": "70d21ed5-5417-42c2-da2c-51c78fe7af1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 28 06:04:09 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P0    31W /  70W |   2736MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download github files"
      ],
      "metadata": {
        "id": "vz21kFuwCvNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/LeslieZhoa/HeadSwap.git\n",
        "%cd HeadSwap/process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5SN8GRf7m6s",
        "outputId": "5967df22-8cb9-4904-e899-744eeb2a5c01"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HeadSwap'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 102 (delta 19), reused 76 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (102/102), 19.71 MiB | 32.82 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n",
            "/content/HeadSwap/HeadSwap/HeadSwap/process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download model path"
      ],
      "metadata": {
        "id": "bXYkmmu-C9zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! bash download_weight.sh\n",
        "! wget https://raw.githubusercontent.com/sicxu/Deep3DFaceRecon_pytorch/master/BFM/similarity_Lm3D_all.mat -P ../pretrained_models/BFM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux_BOlr58Fe8",
        "outputId": "31b0f5ed-c6cd-4c49-c1d3-86de73b4421e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-28 06:04:16--  https://github.com/LeslieZhoa/HeSer.Pytorch/releases/download/v0.0/parsing.pth\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/530152897/e4c87da5-2ba5-43b4-a5d5-24270c4a925c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T060416Z&X-Amz-Expires=300&X-Amz-Signature=f9fc0714069f2a6364579dc0b02f4bc4e4f8eaa2eb370731562b9ca7a57bc638&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=530152897&response-content-disposition=attachment%3B%20filename%3Dparsing.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-28 06:04:16--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/530152897/e4c87da5-2ba5-43b4-a5d5-24270c4a925c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T060416Z&X-Amz-Expires=300&X-Amz-Signature=f9fc0714069f2a6364579dc0b02f4bc4e4f8eaa2eb370731562b9ca7a57bc638&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=530152897&response-content-disposition=attachment%3B%20filename%3Dparsing.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53289463 (51M) [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/parsing.pth’\n",
            "\n",
            "parsing.pth         100%[===================>]  50.82M  14.5MB/s    in 4.1s    \n",
            "\n",
            "2022-12-28 06:04:21 (12.4 MB/s) - ‘../pretrained_models/parsing.pth’ saved [53289463/53289463]\n",
            "\n",
            "--2022-12-28 06:04:21--  https://github.com/LeslieZhoa/HeadSwap/releases/download/v0.0/sr_cf.onnx\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/ceed01af-bdaa-4a77-8599-f41da0a9cebf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T060421Z&X-Amz-Expires=300&X-Amz-Signature=9e061cd7d79cf3c310a579e9c5e3ff4ae453dc6bcd9db5b5e63d0b6cdc665b40&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=580735966&response-content-disposition=attachment%3B%20filename%3Dsr_cf.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-28 06:04:21--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/ceed01af-bdaa-4a77-8599-f41da0a9cebf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T060421Z&X-Amz-Expires=300&X-Amz-Signature=9e061cd7d79cf3c310a579e9c5e3ff4ae453dc6bcd9db5b5e63d0b6cdc665b40&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=580735966&response-content-disposition=attachment%3B%20filename%3Dsr_cf.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 376642743 (359M) [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/sr_cf.onnx’\n",
            "\n",
            "sr_cf.onnx          100%[===================>] 359.19M  98.4MB/s    in 4.5s    \n",
            "\n",
            "2022-12-28 06:04:26 (80.5 MB/s) - ‘../pretrained_models/sr_cf.onnx’ saved [376642743/376642743]\n",
            "\n",
            "--2022-12-28 06:04:26--  https://github.com/LeslieZhoa/HeadSwap/releases/download/v0.0/Blender-401-00012900.pth\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/a967bbbb-08bf-440a-86b0-ff59bfea0867?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T060426Z&X-Amz-Expires=300&X-Amz-Signature=a0d8fb7526aec6c31d8376a6871b8dc8b4e065814fa08e4daeabda557aecedcd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=580735966&response-content-disposition=attachment%3B%20filename%3DBlender-401-00012900.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-28 06:04:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/a967bbbb-08bf-440a-86b0-ff59bfea0867?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T060426Z&X-Amz-Expires=300&X-Amz-Signature=a0d8fb7526aec6c31d8376a6871b8dc8b4e065814fa08e4daeabda557aecedcd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=580735966&response-content-disposition=attachment%3B%20filename%3DBlender-401-00012900.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 788213979 (752M) [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/Blender-401-00012900.pth’\n",
            "\n",
            "Blender-401-0001290 100%[===================>] 751.70M  68.7MB/s    in 11s     \n",
            "\n",
            "2022-12-28 06:04:37 (71.4 MB/s) - ‘../pretrained_models/Blender-401-00012900.pth’ saved [788213979/788213979]\n",
            "\n",
            "--2022-12-28 06:04:37--  https://raw.githubusercontent.com/sicxu/Deep3DFaceRecon_pytorch/master/BFM/similarity_Lm3D_all.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 994 [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/BFM/similarity_Lm3D_all.mat’\n",
            "\n",
            "similarity_Lm3D_all 100%[===================>]     994  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-28 06:04:37 (53.8 MB/s) - ‘../pretrained_models/BFM/similarity_Lm3D_all.mat’ saved [994/994]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup files downloader\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "download_with_pydrive = True #@param {type:\"boolean\"}\n",
        "\n",
        "class Downloader(object):\n",
        "    def __init__(self, use_pydrive):\n",
        "        self.use_pydrive = use_pydrive\n",
        "        current_directory = os.getcwd()\n",
        "        self.save_dir = '../pretrained_models'\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "        if self.use_pydrive:\n",
        "            self.authenticate()\n",
        "\n",
        "    def authenticate(self):\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        self.drive = GoogleDrive(gauth)\n",
        "\n",
        "    def download_file(self, file_id, file_name):\n",
        "        file_dst = f'{self.save_dir}/{file_name}'\n",
        "        if os.path.exists(file_dst):\n",
        "            print(f'{file_name} already exists!')\n",
        "            return\n",
        "        if self.use_pydrive:\n",
        "            downloaded = self.drive.CreateFile({'id':file_id})\n",
        "            downloaded.FetchMetadata(fetch_all=True)\n",
        "            downloaded.GetContentFile(file_dst)\n",
        "        else:\n",
        "            !gdown --id $file_id -O $file_dst\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)"
      ],
      "metadata": {
        "id": "MGEEwCHZCohn"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download epoch_20\n",
        "MODEL_PATHS = {\"id\": \"1BlDBB4dLLrlN3cJhVL4nmrd_g6Jx6uP0\", \"name\": \"epoch_20.pth\"}\n",
        "   \n",
        "downloader.download_file(file_id=MODEL_PATHS[\"id\"], file_name=MODEL_PATHS[\"name\"])"
      ],
      "metadata": {
        "id": "gd0BrM1rDO3a"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download PIRender model"
      ],
      "metadata": {
        "id": "n5drU3CIUEY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATHS = {\"id\": \"1-0xOf6g58OmtKtEWJlU3VlnfRqPN9Uq7\", \"name\": \"face.zip\"}   \n",
        "downloader.download_file(file_id=MODEL_PATHS[\"id\"], file_name=MODEL_PATHS[\"name\"])\n",
        "! unzip -x ../pretrained_models/face.zip\n",
        "! mv ../pretrained_models/face/epoch_00190_iteration_000400000_checkpoint.pt  ../pretrained_models"
      ],
      "metadata": {
        "id": "hL8N3M_DUD3m",
        "outputId": "e1e4e8a4-675b-4804-fcd4-922841325ab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "face.zip already exists!\n",
            "Archive:  ../pretrained_models/face.zip\n",
            "replace face/epoch_00190_iteration_000400000_checkpoint.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: face/epoch_00190_iteration_000400000_checkpoint.pt  \n",
            "replace face/latest_checkpoint.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: face/latest_checkpoint.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## enviroment"
      ],
      "metadata": {
        "id": "8lCGm7VnDc02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch torchvision numpy opencv-python onnxruntime-gpu face-alignment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzfacabV9Bzq",
        "outputId": "87ec6dd1-5200-4f2b-daca-469fc6089a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.8/dist-packages (1.13.1)\n",
            "Requirement already satisfied: face-alignment in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (21.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (3.19.6)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.7.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from face-alignment) (0.18.3)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from face-alignment) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from face-alignment) (4.64.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from face-alignment) (0.56.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.8/dist-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba->face-alignment) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->face-alignment) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->face-alignment) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->face-alignment) (3.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->onnxruntime-gpu) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (2022.10.10)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (2.8.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.15.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime-gpu) (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypt-WwwU-S3l",
        "outputId": "a4bb08f2-f2da-4e83-d2aa-3579bd06a402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HeadSwap/HeadSwap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model.AlignModule.generator import FaceGenerator\n",
        "from model.BlendModule.generator import Generator as Decoder\n",
        "from model.AlignModule.config import Params as AlignParams\n",
        "from model.BlendModule.config import Params as BlendParams \n",
        "from model.third.faceParsing.model import BiSeNet\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pdb\n",
        "from process.process_func import Process\n",
        "from process.process_utils import *\n",
        "import os\n",
        "import onnxruntime as ort\n"
      ],
      "metadata": {
        "id": "d1nd1n23-ZET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Infer(Process):\n",
        "    def __init__(self,align_path,blend_path,parsing_path,params_path,bfm_folder):\n",
        "        Process.__init__(self,params_path,bfm_folder)\n",
        "        align_params = AlignParams()\n",
        "        blend_params = BlendParams()\n",
        "        self.device = 'cpu'\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = 'cuda'\n",
        "      \n",
        "        self.parsing = BiSeNet(n_classes=19).to(self.device)\n",
        "        \n",
        "        self.netG = FaceGenerator(align_params).to(self.device)\n",
        "        self.decoder = Decoder(blend_params).to(self.device)\n",
        "        \n",
        "        self.loadModel(align_path,blend_path,parsing_path)\n",
        "        self.eval_model(self.netG,self.decoder,self.parsing)\n",
        "        \n",
        "\n",
        "        self.ort_session_sr = ort.InferenceSession('./pretrained_models/sr_cf.onnx', providers=['CPUExecutionProvider'])\n",
        "\n",
        "    def run(self,src_img_path_list,tgt_img_path_list,save_base,crop_align=False,cat=False):\n",
        "        os.makedirs(save_base,exist_ok=True)\n",
        "        i = 0\n",
        "        for src_img_path,tgt_img_path in zip(src_img_path_list,tgt_img_path_list):\n",
        "            gen = self.run_single(src_img_path,tgt_img_path,crop_align=crop_align,cat=cat)\n",
        "            img_name = os.path.splitext(os.path.basename(src_img_path))[0]+'-' + \\\n",
        "                        os.path.splitext(os.path.basename(tgt_img_path))[0]+'.png'\n",
        "            cv2.imwrite(os.path.join(save_base,img_name),gen)\n",
        "            print('\\rhave done %04d'%i,end='',flush=True)\n",
        "            i += 1\n",
        "        print()\n",
        "    def run_single(self,src_img_path,tgt_img_path,crop_align=False,cat=False):\n",
        "        \n",
        "        tgt_img = cv2.imread(tgt_img_path)\n",
        "        tgt_align = tgt_img.copy()\n",
        "        \n",
        "        tgt_align,info = self.preprocess_align(tgt_img)\n",
        "        if tgt_align is None:\n",
        "            return None\n",
        "\n",
        "        src_img = cv2.imread(src_img_path)\n",
        "        src_align = src_img\n",
        "        if crop_align:\n",
        "            src_align,_ = self.preprocess_align(src_img,top_scale=0.55)\n",
        "        \n",
        "        src_inp = self.preprocess(src_align)\n",
        "        tgt_inp = self.preprocess(tgt_align)\n",
        "\n",
        "        tgt_params = self.get_params(cv2.resize(tgt_align,(256,256)),\n",
        "                                info['rotated_lmk']/2.0).unsqueeze(0)\n",
        "           \n",
        "        gen = self.forward(src_inp,tgt_inp,tgt_params) \n",
        "\n",
        "        gen = self.postprocess(gen[0])\n",
        "        gen = self.run_sr(gen)\n",
        "        mask = self.mask\n",
        "        final = gen\n",
        "        # gen = color_transfer2(tgt_align,gen)\n",
        "            \n",
        "        RotateMatrix = info['im'][:2]\n",
        "        mask = info['mask'][...,0]\n",
        "       \n",
        "        rotate_gen = cv2.warpAffine(gen, RotateMatrix, (tgt_img.shape[1], tgt_img.shape[0]))\n",
        "        mask = cv2.warpAffine(mask, RotateMatrix, (tgt_img.shape[1], tgt_img.shape[0])) * 1.0\n",
        "\n",
        "        # ori_mask = mask.copy()\n",
        "        kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT,(17, 17))\n",
        "        # mask = cv2.dilate(mask*1.0,kernel2)\n",
        "        mask = cv2.erode(mask*1.0,kernel2)\n",
        "        # mask = cv2.GaussianBlur(mask*255.0, (21, 21), 0) / 255.0\n",
        "        mask = cv2.blur(mask*1.0, (15, 15), 0) / 255.0\n",
        "        mask = np.clip(mask,0,1.0)[:,:,np.newaxis]\n",
        "\n",
        "        # pdb.set_trace()\n",
        "        final = rotate_gen * mask + tgt_img * (1-mask)\n",
        "\n",
        "        if cat:\n",
        "            final = np.concatenate([tgt_img,final],1)\n",
        "            final[-256:,:256] = cv2.resize(src_align,(256,256))\n",
        "\n",
        "        return final\n",
        "    \n",
        "    def forward(self,xs,xt,params):\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # xg = self.netG(F.adaptive_avg_pool2d(xs,256),\n",
        "            #                 F.adaptive_avg_pool2d(xt,256),\n",
        "            #                 params)['fake_image']\n",
        "            xg = F.adaptive_avg_pool2d(self.netG(F.adaptive_avg_pool2d(xs,256),\n",
        "                            F.adaptive_avg_pool2d(xt,256),\n",
        "                            params)['fake_image'],512)\n",
        "           \n",
        "            \n",
        "            M_a = self.parsing(self.preprocess_parsing(xg))\n",
        "           \n",
        "            M_t = self.parsing(self.preprocess_parsing(xt))\n",
        "            \n",
        "            M_a = self.postprocess_parsing(M_a)\n",
        "            M_t = self.postprocess_parsing(M_t)\n",
        "            # xg[M_a.repeat(1,3,1,1)==0] = -0.5\n",
        "            # xg[M_a.repeat(1,3,1,1)==16] = 0.6\n",
        "            xg_gray = TF.rgb_to_grayscale(xg,num_output_channels=1)\n",
        "            fake = self.decoder(xg,xg_gray,xt,M_a,M_t,xt,train=False)\n",
        "            \n",
        "            \n",
        "            gen_mask = self.parsing(self.preprocess_parsing(fake))\n",
        "            gen_mask = self.postprocess_parsing(gen_mask)\n",
        "            gen_mask = gen_mask[0][0].cpu().numpy()\n",
        "            mask_t = M_t[0][0].cpu().numpy()\n",
        "            mask = np.zeros_like(gen_mask)\n",
        "            for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,17,18]:\n",
        "                mask[gen_mask==i] = 1.0\n",
        "                mask[mask_t==i] = 1.0\n",
        "            \n",
        "            self.mask = mask\n",
        "        return fake\n",
        "    \n",
        "    def run_sr(self,input_np):\n",
        "        input_np = cv2.cvtColor(input_np, cv2.COLOR_BGR2RGB)\n",
        "        # prepare data\n",
        "        input_np = input_np.transpose((2,0,1))\n",
        "        input_np = np.array(input_np[np.newaxis, :])\n",
        "        outputs_onnx = self.ort_session_sr.run(None, {'input_image':input_np.astype(np.uint8)})\n",
        "\n",
        "        out_put_onnx = outputs_onnx[0]\n",
        "        outimg = out_put_onnx[0,...].transpose(1,2,0)\n",
        "        outimg = cv2.cvtColor(outimg, cv2.COLOR_BGR2RGB)\n",
        "        return outimg\n",
        "\n",
        "        \n",
        "    def loadModel(self,align_path,blend_path,parsing_path):\n",
        "        ckpt = torch.load(align_path, map_location=lambda storage, loc: storage)\n",
        "        # self.netG.load_state_dict(ckpt['G'])\n",
        "        self.netG.load_state_dict(ckpt['net_G_ema'])\n",
        "\n",
        "        ckpt = torch.load(blend_path, map_location=lambda storage, loc: storage)\n",
        "        self.decoder.load_state_dict(ckpt['G'],strict=False)\n",
        "\n",
        "        self.parsing.load_state_dict(torch.load(parsing_path))\n",
        "\n",
        "    \n",
        "    def eval_model(self,*args):\n",
        "        for arg in args:\n",
        "            arg.eval()\n"
      ],
      "metadata": {
        "id": "0ymbJWEq-edY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Infer(\n",
        "            # 'checkpoint/Aligner/058-00008100.pth',\n",
        "            'pretrained_models/epoch_00190_iteration_000400000_checkpoint.pt',\n",
        "            'pretrained_models/Blender-401-00012900.pth',\n",
        "            'pretrained_models/parsing.pth',\n",
        "            'pretrained_models/epoch_20.pth',\n",
        "            'pretrained_models/BFM')\n",
        "\n",
        "# find_path = lambda x: [os.path.join(x,f) for f in os.listdir(x)]\n",
        "# img_paths = find_path('../HeadSwap/test_img')[::-1]\n",
        "\n",
        "src_paths = ['./assets/5.jpg']\n",
        "tgt_paths = ['assets/fe54875c-2cf0-4147-b08a-80552a9f46be.jpg']\n",
        "\n",
        "model.run(src_paths,tgt_paths,save_base='res-1125',crop_align=True,cat=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "kkagbZIP_ZAQ",
        "outputId": "ef587c49-01af-4def-edd9-b5e626b68c03"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-5ac6d5f3c7a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' cd ..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = Infer(\n\u001b[0m\u001b[1;32m      3\u001b[0m             \u001b[0;31m# 'checkpoint/Aligner/058-00008100.pth',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;34m'pretrained_models/epoch_00190_iteration_000400000_checkpoint.pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m'pretrained_models/Blender-401-00012900.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-267e6b1e17d7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, align_path, blend_path, parsing_path, params_path, bfm_folder)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mInfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malign_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblend_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparsing_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbfm_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbfm_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0malign_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlignParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mblend_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlendParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/HeadSwap/process/process_func.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params_path, bfm_folder)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParamsModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReconNetWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParamsModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParamsModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'net_recon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm3d_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_lm3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbfm_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.485\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.456\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.406\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pretrained_models/epoch_20.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l pretrained_models/BFM"
      ],
      "metadata": {
        "id": "eWLI6T-9_d_C",
        "outputId": "1544e782-a620-4ad6-f3a2-b4d4647e0372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 140\n",
            "-rw-r--r-- 1 root root 140235 Dec 28 04:58 similarity_Lm3D_all.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWPDTpQ_BkcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://drive.google.com/drive/folders/1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP -P pretrained_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CHS6gypCVLe",
        "outputId": "ce4ded92-a33c-46e4-c6f6-98c61f7f9c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-28 05:07:24--  https://drive.google.com/drive/folders/1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.194.100, 173.194.194.139, 173.194.194.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.194.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘pretrained_models/1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP’\n",
            "\n",
            "\r          1liaIxn9s     [<=>                 ]       0  --.-KB/s               \r1liaIxn9smpudjjqMaW     [ <=>                ] 231.83K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-12-28 05:07:24 (2.84 MB/s) - ‘pretrained_models/1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP’ saved [237398]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l pretrained_models/"
      ],
      "metadata": {
        "id": "SDhgLURACaiT",
        "outputId": "9b4e73d8-165e-4a90-bb62-3ef0d954de79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1471940\n",
            "-rw-r--r-- 1 root root    237398 Dec 28 05:07 1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP\n",
            "drwxr-xr-x 2 root root      4096 Dec 28 04:58 BFM\n",
            "-rw-r--r-- 1 root root 788213979 Dec 21 14:10 Blender-401-00012900.pth\n",
            "-rw-r--r-- 1 root root 288860037 Dec 28 05:50 epoch_20.pth\n",
            "-rw-r--r-- 1 root root  53289463 Aug 30 08:51 parsing.pth\n",
            "-rw-r--r-- 1 root root 376642743 Dec 21 13:19 sr_cf.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l"
      ],
      "metadata": {
        "id": "QzUbX9ZCIO4R",
        "outputId": "8947f7a9-a34d-4801-9d9a-b6cf67678b96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 276\n",
            "drwxr-xr-x 2 root root  4096 Dec 28 04:56  assets\n",
            "drwxr-xr-x 3 root root  4096 Dec 28 05:00  dataloader\n",
            "-rw-r--r-- 1 root root 74124 Dec 28 05:49  epoch_20.pth\n",
            "-rw-r--r-- 1 root root  7005 Dec 28 04:56  inference.py\n",
            "-rw-r--r-- 1 root root 75762 Dec 28 04:56  infer.ipynb\n",
            "-rw-r--r-- 1 root root  1067 Dec 28 04:56  LICENSE\n",
            "drwxr-xr-x 5 root root  4096 Dec 28 04:56  model\n",
            "drwxr-xr-x 3 root root  4096 Dec 28 05:50  pretrained_models\n",
            "drwxr-xr-x 3 root root  4096 Dec 28 05:00  process\n",
            "-rw-r--r-- 1 root root  2883 Dec 28 04:56  ReadMe.md\n",
            "drwxr-xr-x 2 root root  4096 Dec 28 04:56  trainer\n",
            "-rw-r--r-- 1 root root  3702 Dec 28 04:56  train.py\n",
            "drwxr-xr-x 3 root root  4096 Dec 28 05:00  utils\n",
            "-rw-r--r-- 1 root root 74130 Dec 28 05:47 'view?usp=share_link'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4K3I6r3DReB7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}