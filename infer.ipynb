{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM8zhiV8XrbR+4qM7Yfgf2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeslieZhoa/HeadSwap/blob/main/infer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZfYoKXr6rxi",
        "outputId": "ebfb8997-75b9-42d3-f02e-9575b9ff084d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 28 04:56:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P0    29W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download github files"
      ],
      "metadata": {
        "id": "vz21kFuwCvNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/LeslieZhoa/HeadSwap.git\n",
        "%cd HeadSwap/process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5SN8GRf7m6s",
        "outputId": "fbabcb6c-881b-42ca-9a01-b87bd8d68d2b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HeadSwap'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 96 (delta 15), reused 76 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (96/96), done.\n",
            "/content/HeadSwap/process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download model path"
      ],
      "metadata": {
        "id": "bXYkmmu-C9zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! bash download_weight.sh\n",
        "! wget https://github.com/sicxu/Deep3DFaceRecon_pytorch/blob/master/BFM/similarity_Lm3D_all.mat -P ../pretrained_models/BFM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux_BOlr58Fe8",
        "outputId": "d59ee0d2-07db-4879-b126-053e22f924ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-28 04:58:13--  https://github.com/LeslieZhoa/HeSer.Pytorch/releases/download/v0.0/parsing.pth\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/530152897/e4c87da5-2ba5-43b4-a5d5-24270c4a925c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T045813Z&X-Amz-Expires=300&X-Amz-Signature=a28acef7acfaa1373ae6a6c389430d68841066b1359b0daf0e3fdd1b962c4a45&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=530152897&response-content-disposition=attachment%3B%20filename%3Dparsing.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-28 04:58:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/530152897/e4c87da5-2ba5-43b4-a5d5-24270c4a925c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T045813Z&X-Amz-Expires=300&X-Amz-Signature=a28acef7acfaa1373ae6a6c389430d68841066b1359b0daf0e3fdd1b962c4a45&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=530152897&response-content-disposition=attachment%3B%20filename%3Dparsing.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53289463 (51M) [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/parsing.pth’\n",
            "\n",
            "parsing.pth         100%[===================>]  50.82M  90.9MB/s    in 0.6s    \n",
            "\n",
            "2022-12-28 04:58:14 (90.9 MB/s) - ‘../pretrained_models/parsing.pth’ saved [53289463/53289463]\n",
            "\n",
            "--2022-12-28 04:58:14--  https://github.com/LeslieZhoa/HeadSwap/releases/download/v0.0/sr_cf.onnx\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/ceed01af-bdaa-4a77-8599-f41da0a9cebf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T045814Z&X-Amz-Expires=300&X-Amz-Signature=40e77bba6b142117ea940a12f1335c001bfb69d0ff2e87aae38d880d11f15ccb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=580735966&response-content-disposition=attachment%3B%20filename%3Dsr_cf.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-28 04:58:14--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/ceed01af-bdaa-4a77-8599-f41da0a9cebf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T045814Z&X-Amz-Expires=300&X-Amz-Signature=40e77bba6b142117ea940a12f1335c001bfb69d0ff2e87aae38d880d11f15ccb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=580735966&response-content-disposition=attachment%3B%20filename%3Dsr_cf.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 376642743 (359M) [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/sr_cf.onnx’\n",
            "\n",
            "sr_cf.onnx          100%[===================>] 359.19M  19.1MB/s    in 13s     \n",
            "\n",
            "2022-12-28 04:58:28 (27.0 MB/s) - ‘../pretrained_models/sr_cf.onnx’ saved [376642743/376642743]\n",
            "\n",
            "--2022-12-28 04:58:28--  https://github.com/LeslieZhoa/HeadSwap/releases/download/v0.0/Blender-401-00012900.pth\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/a967bbbb-08bf-440a-86b0-ff59bfea0867?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T045828Z&X-Amz-Expires=300&X-Amz-Signature=ef82681c2e79970bfa7c12f1d4579f062b079940445e64d2342aabe3fa27d21b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=580735966&response-content-disposition=attachment%3B%20filename%3DBlender-401-00012900.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-28 04:58:28--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/a967bbbb-08bf-440a-86b0-ff59bfea0867?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T045828Z&X-Amz-Expires=300&X-Amz-Signature=ef82681c2e79970bfa7c12f1d4579f062b079940445e64d2342aabe3fa27d21b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=580735966&response-content-disposition=attachment%3B%20filename%3DBlender-401-00012900.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 788213979 (752M) [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/Blender-401-00012900.pth’\n",
            "\n",
            "Blender-401-0001290 100%[===================>] 751.70M  23.3MB/s    in 21s     \n",
            "\n",
            "2022-12-28 04:58:49 (36.0 MB/s) - ‘../pretrained_models/Blender-401-00012900.pth’ saved [788213979/788213979]\n",
            "\n",
            "--2022-12-28 04:58:49--  https://github.com/sicxu/Deep3DFaceRecon_pytorch/blob/master/BFM/similarity_Lm3D_all.mat\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘../pretrained_models/BFM/similarity_Lm3D_all.mat’\n",
            "\n",
            "similarity_Lm3D_all     [ <=>                ] 136.95K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-12-28 04:58:50 (1.80 MB/s) - ‘../pretrained_models/BFM/similarity_Lm3D_all.mat’ saved [140235]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup files downloader\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "download_with_pydrive = True #@param {type:\"boolean\"}\n",
        "\n",
        "class Downloader(object):\n",
        "    def __init__(self, use_pydrive):\n",
        "        self.use_pydrive = use_pydrive\n",
        "        current_directory = os.getcwd()\n",
        "        self.save_dir = 'pretrained_models'\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "        if self.use_pydrive:\n",
        "            self.authenticate()\n",
        "\n",
        "    def authenticate(self):\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        self.drive = GoogleDrive(gauth)\n",
        "\n",
        "    def download_file(self, file_id, file_name):\n",
        "        file_dst = f'{self.save_dir}/{file_name}'\n",
        "        if os.path.exists(file_dst):\n",
        "            print(f'{file_name} already exists!')\n",
        "            return\n",
        "        if self.use_pydrive:\n",
        "            downloaded = self.drive.CreateFile({'id':file_id})\n",
        "            downloaded.FetchMetadata(fetch_all=True)\n",
        "            downloaded.GetContentFile(file_dst)\n",
        "        else:\n",
        "            !gdown --id $file_id -O $file_dst\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)"
      ],
      "metadata": {
        "id": "MGEEwCHZCohn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download epoch_20\n",
        "MODEL_PATHS = {\"id\": \"1BlDBB4dLLrlN3cJhVL4nmrd_g6Jx6uP0\", \"name\": \"epoch_20.pth\"}\n",
        "   \n",
        "downloader.download_file(file_id=MODEL_PATHS[\"id\"], file_name=MODEL_PATHS[\"name\"])"
      ],
      "metadata": {
        "id": "gd0BrM1rDO3a"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## enviroment"
      ],
      "metadata": {
        "id": "8lCGm7VnDc02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch torchvision numpy opencv-python onnxruntime-gpu face-alignment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzfacabV9Bzq",
        "outputId": "79517b66-5bab-4b22-8cd7-2a0dc916ec5f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 115.3 MB 35 kB/s \n",
            "\u001b[?25hCollecting face-alignment\n",
            "  Downloading face_alignment-1.3.5.tar.gz (27 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (21.3)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.12)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.7.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (3.19.6)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from face-alignment) (1.7.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from face-alignment) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from face-alignment) (4.64.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from face-alignment) (0.56.4)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->face-alignment) (5.1.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->face-alignment) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba->face-alignment) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->face-alignment) (3.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->onnxruntime-gpu) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (2022.10.10)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (2.8.8)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (2.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.15.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime-gpu) (1.2.1)\n",
            "Building wheels for collected packages: face-alignment\n",
            "  Building wheel for face-alignment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-alignment: filename=face_alignment-1.3.5-py2.py3-none-any.whl size=28242 sha256=b1d995635b153a606738c8ecda9ef1173979d93907abfdb93121a4332521145d\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/21/d8/7bf61c86e3a6c5af8f118708d4c9c26512dbd1c913a0b97c8a\n",
            "Successfully built face-alignment\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime-gpu, face-alignment\n",
            "Successfully installed coloredlogs-15.0.1 face-alignment-1.3.5 humanfriendly-10.0 onnxruntime-gpu-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypt-WwwU-S3l",
        "outputId": "2e365c61-ab48-49e5-a540-9e3ee1094dd9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HeadSwap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model.AlignModule.generator import FaceGenerator\n",
        "from model.BlendModule.generator import Generator as Decoder\n",
        "from model.AlignModule.config import Params as AlignParams\n",
        "from model.BlendModule.config import Params as BlendParams \n",
        "from model.third.faceParsing.model import BiSeNet\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pdb\n",
        "from process.process_func import Process\n",
        "from process.process_utils import *\n",
        "import os\n",
        "import onnxruntime as ort\n"
      ],
      "metadata": {
        "id": "d1nd1n23-ZET"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Infer(Process):\n",
        "    def __init__(self,align_path,blend_path,parsing_path,params_path,bfm_folder):\n",
        "        Process.__init__(self,params_path,bfm_folder)\n",
        "        align_params = AlignParams()\n",
        "        blend_params = BlendParams()\n",
        "        self.device = 'cpu'\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = 'cuda'\n",
        "      \n",
        "        self.parsing = BiSeNet(n_classes=19).to(self.device)\n",
        "        \n",
        "        self.netG = FaceGenerator(align_params).to(self.device)\n",
        "        self.decoder = Decoder(blend_params).to(self.device)\n",
        "        \n",
        "        self.loadModel(align_path,blend_path,parsing_path)\n",
        "        self.eval_model(self.netG,self.decoder,self.parsing)\n",
        "        \n",
        "\n",
        "        self.ort_session_sr = ort.InferenceSession('./pretrained_models/sr_cf.onnx', providers=['CPUExecutionProvider'])\n",
        "\n",
        "    def run(self,src_img_path_list,tgt_img_path_list,save_base,crop_align=False,cat=False):\n",
        "        os.makedirs(save_base,exist_ok=True)\n",
        "        i = 0\n",
        "        for src_img_path,tgt_img_path in zip(src_img_path_list,tgt_img_path_list):\n",
        "            gen = self.run_single(src_img_path,tgt_img_path,crop_align=crop_align,cat=cat)\n",
        "            img_name = os.path.splitext(os.path.basename(src_img_path))[0]+'-' + \\\n",
        "                        os.path.splitext(os.path.basename(tgt_img_path))[0]+'.png'\n",
        "            cv2.imwrite(os.path.join(save_base,img_name),gen)\n",
        "            print('\\rhave done %04d'%i,end='',flush=True)\n",
        "            i += 1\n",
        "        print()\n",
        "    def run_single(self,src_img_path,tgt_img_path,crop_align=False,cat=False):\n",
        "        \n",
        "        tgt_img = cv2.imread(tgt_img_path)\n",
        "        tgt_align = tgt_img.copy()\n",
        "        \n",
        "        tgt_align,info = self.preprocess_align(tgt_img)\n",
        "        if tgt_align is None:\n",
        "            return None\n",
        "\n",
        "        src_img = cv2.imread(src_img_path)\n",
        "        src_align = src_img\n",
        "        if crop_align:\n",
        "            src_align,_ = self.preprocess_align(src_img,top_scale=0.55)\n",
        "        \n",
        "        src_inp = self.preprocess(src_align)\n",
        "        tgt_inp = self.preprocess(tgt_align)\n",
        "\n",
        "        tgt_params = self.get_params(cv2.resize(tgt_align,(256,256)),\n",
        "                                info['rotated_lmk']/2.0).unsqueeze(0)\n",
        "           \n",
        "        gen = self.forward(src_inp,tgt_inp,tgt_params) \n",
        "\n",
        "        gen = self.postprocess(gen[0])\n",
        "        gen = self.run_sr(gen)\n",
        "        mask = self.mask\n",
        "        final = gen\n",
        "        # gen = color_transfer2(tgt_align,gen)\n",
        "            \n",
        "        RotateMatrix = info['im'][:2]\n",
        "        mask = info['mask'][...,0]\n",
        "       \n",
        "        rotate_gen = cv2.warpAffine(gen, RotateMatrix, (tgt_img.shape[1], tgt_img.shape[0]))\n",
        "        mask = cv2.warpAffine(mask, RotateMatrix, (tgt_img.shape[1], tgt_img.shape[0])) * 1.0\n",
        "\n",
        "        # ori_mask = mask.copy()\n",
        "        kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT,(17, 17))\n",
        "        # mask = cv2.dilate(mask*1.0,kernel2)\n",
        "        mask = cv2.erode(mask*1.0,kernel2)\n",
        "        # mask = cv2.GaussianBlur(mask*255.0, (21, 21), 0) / 255.0\n",
        "        mask = cv2.blur(mask*1.0, (15, 15), 0) / 255.0\n",
        "        mask = np.clip(mask,0,1.0)[:,:,np.newaxis]\n",
        "\n",
        "        # pdb.set_trace()\n",
        "        final = rotate_gen * mask + tgt_img * (1-mask)\n",
        "\n",
        "        if cat:\n",
        "            final = np.concatenate([tgt_img,final],1)\n",
        "            final[-256:,:256] = cv2.resize(src_align,(256,256))\n",
        "\n",
        "        return final\n",
        "    \n",
        "    def forward(self,xs,xt,params):\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # xg = self.netG(F.adaptive_avg_pool2d(xs,256),\n",
        "            #                 F.adaptive_avg_pool2d(xt,256),\n",
        "            #                 params)['fake_image']\n",
        "            xg = F.adaptive_avg_pool2d(self.netG(F.adaptive_avg_pool2d(xs,256),\n",
        "                            F.adaptive_avg_pool2d(xt,256),\n",
        "                            params)['fake_image'],512)\n",
        "           \n",
        "            \n",
        "            M_a = self.parsing(self.preprocess_parsing(xg))\n",
        "           \n",
        "            M_t = self.parsing(self.preprocess_parsing(xt))\n",
        "            \n",
        "            M_a = self.postprocess_parsing(M_a)\n",
        "            M_t = self.postprocess_parsing(M_t)\n",
        "            # xg[M_a.repeat(1,3,1,1)==0] = -0.5\n",
        "            # xg[M_a.repeat(1,3,1,1)==16] = 0.6\n",
        "            xg_gray = TF.rgb_to_grayscale(xg,num_output_channels=1)\n",
        "            fake = self.decoder(xg,xg_gray,xt,M_a,M_t,xt,train=False)\n",
        "            \n",
        "            \n",
        "            gen_mask = self.parsing(self.preprocess_parsing(fake))\n",
        "            gen_mask = self.postprocess_parsing(gen_mask)\n",
        "            gen_mask = gen_mask[0][0].cpu().numpy()\n",
        "            mask_t = M_t[0][0].cpu().numpy()\n",
        "            mask = np.zeros_like(gen_mask)\n",
        "            for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,17,18]:\n",
        "                mask[gen_mask==i] = 1.0\n",
        "                mask[mask_t==i] = 1.0\n",
        "            \n",
        "            self.mask = mask\n",
        "        return fake\n",
        "    \n",
        "    def run_sr(self,input_np):\n",
        "        input_np = cv2.cvtColor(input_np, cv2.COLOR_BGR2RGB)\n",
        "        # prepare data\n",
        "        input_np = input_np.transpose((2,0,1))\n",
        "        input_np = np.array(input_np[np.newaxis, :])\n",
        "        outputs_onnx = self.ort_session_sr.run(None, {'input_image':input_np.astype(np.uint8)})\n",
        "\n",
        "        out_put_onnx = outputs_onnx[0]\n",
        "        outimg = out_put_onnx[0,...].transpose(1,2,0)\n",
        "        outimg = cv2.cvtColor(outimg, cv2.COLOR_BGR2RGB)\n",
        "        return outimg\n",
        "\n",
        "        \n",
        "    def loadModel(self,align_path,blend_path,parsing_path):\n",
        "        ckpt = torch.load(align_path, map_location=lambda storage, loc: storage)\n",
        "        # self.netG.load_state_dict(ckpt['G'])\n",
        "        self.netG.load_state_dict(ckpt['net_G_ema'])\n",
        "\n",
        "        ckpt = torch.load(blend_path, map_location=lambda storage, loc: storage)\n",
        "        self.decoder.load_state_dict(ckpt['G'],strict=False)\n",
        "\n",
        "        self.parsing.load_state_dict(torch.load(parsing_path))\n",
        "\n",
        "    \n",
        "    def eval_model(self,*args):\n",
        "        for arg in args:\n",
        "            arg.eval()\n"
      ],
      "metadata": {
        "id": "0ymbJWEq-edY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Infer(\n",
        "            # 'checkpoint/Aligner/058-00008100.pth',\n",
        "            'pretrained_models/epoch_00190_iteration_000400000_checkpoint.pt',\n",
        "            'pretrained_models/Blender-401-00012900.pth',\n",
        "            'pretrained_models/parsing.pth',\n",
        "            'pretrained_models/epoch_20.pth',\n",
        "            'pretrained_models/BFM')\n",
        "\n",
        "# find_path = lambda x: [os.path.join(x,f) for f in os.listdir(x)]\n",
        "# img_paths = find_path('../HeadSwap/test_img')[::-1]\n",
        "\n",
        "src_paths = ['./assets/5.jpg']\n",
        "tgt_paths = ['assets/fe54875c-2cf0-4147-b08a-80552a9f46be.jpg']\n",
        "\n",
        "model.run(src_paths,tgt_paths,save_base='res-1125',crop_align=True,cat=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kkagbZIP_ZAQ",
        "outputId": "8f4c4f53-5346-433c-9826-46d0021b2757"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-6349e095f330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = Infer(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0;31m# 'checkpoint/Aligner/058-00008100.pth',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0;34m'pretrained_models/epoch_00190_iteration_000400000_checkpoint.pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;34m'pretrained_models/Blender-401-00012900.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m'pretrained_models/parsing.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-267e6b1e17d7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, align_path, blend_path, parsing_path, params_path, bfm_folder)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mInfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malign_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblend_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparsing_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbfm_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbfm_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0malign_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlignParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mblend_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlendParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/HeadSwap/process/process_func.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params_path, bfm_folder)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParamsModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParamsModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'net_recon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm3d_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_lm3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbfm_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.485\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.456\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.406\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.229\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.225\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/HeadSwap/model/third/Deep3dRec/preprocess.py\u001b[0m in \u001b[0;36mload_lm3d\u001b[0;34m(bfm_folder)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_lm3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbfm_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mLm3D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbfm_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'similarity_Lm3D_all.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mLm3D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLm3D\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[0;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \"\"\"\n\u001b[1;32m     73\u001b[0m     \u001b[0mbyte_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mmjv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatFile4Reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/io/matlab/miobase.py\u001b[0m in \u001b[0;36mget_matfile_version\u001b[0;34m(fileobj)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaj_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown mat file type, version %s, %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown mat file type, version 97, 116"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l pretrained_models/BFM"
      ],
      "metadata": {
        "id": "eWLI6T-9_d_C",
        "outputId": "1544e782-a620-4ad6-f3a2-b4d4647e0372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 140\n",
            "-rw-r--r-- 1 root root 140235 Dec 28 04:58 similarity_Lm3D_all.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWPDTpQ_BkcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://drive.google.com/drive/folders/1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP -P pretrained_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CHS6gypCVLe",
        "outputId": "ce4ded92-a33c-46e4-c6f6-98c61f7f9c37"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-28 05:07:24--  https://drive.google.com/drive/folders/1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.194.100, 173.194.194.139, 173.194.194.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.194.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘pretrained_models/1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP’\n",
            "\n",
            "\r          1liaIxn9s     [<=>                 ]       0  --.-KB/s               \r1liaIxn9smpudjjqMaW     [ <=>                ] 231.83K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-12-28 05:07:24 (2.84 MB/s) - ‘pretrained_models/1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP’ saved [237398]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l pretrained_models/"
      ],
      "metadata": {
        "id": "SDhgLURACaiT",
        "outputId": "9b4e73d8-165e-4a90-bb62-3ef0d954de79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1471940\n",
            "-rw-r--r-- 1 root root    237398 Dec 28 05:07 1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP\n",
            "drwxr-xr-x 2 root root      4096 Dec 28 04:58 BFM\n",
            "-rw-r--r-- 1 root root 788213979 Dec 21 14:10 Blender-401-00012900.pth\n",
            "-rw-r--r-- 1 root root 288860037 Dec 28 05:50 epoch_20.pth\n",
            "-rw-r--r-- 1 root root  53289463 Aug 30 08:51 parsing.pth\n",
            "-rw-r--r-- 1 root root 376642743 Dec 21 13:19 sr_cf.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l"
      ],
      "metadata": {
        "id": "QzUbX9ZCIO4R",
        "outputId": "8947f7a9-a34d-4801-9d9a-b6cf67678b96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 276\n",
            "drwxr-xr-x 2 root root  4096 Dec 28 04:56  assets\n",
            "drwxr-xr-x 3 root root  4096 Dec 28 05:00  dataloader\n",
            "-rw-r--r-- 1 root root 74124 Dec 28 05:49  epoch_20.pth\n",
            "-rw-r--r-- 1 root root  7005 Dec 28 04:56  inference.py\n",
            "-rw-r--r-- 1 root root 75762 Dec 28 04:56  infer.ipynb\n",
            "-rw-r--r-- 1 root root  1067 Dec 28 04:56  LICENSE\n",
            "drwxr-xr-x 5 root root  4096 Dec 28 04:56  model\n",
            "drwxr-xr-x 3 root root  4096 Dec 28 05:50  pretrained_models\n",
            "drwxr-xr-x 3 root root  4096 Dec 28 05:00  process\n",
            "-rw-r--r-- 1 root root  2883 Dec 28 04:56  ReadMe.md\n",
            "drwxr-xr-x 2 root root  4096 Dec 28 04:56  trainer\n",
            "-rw-r--r-- 1 root root  3702 Dec 28 04:56  train.py\n",
            "drwxr-xr-x 3 root root  4096 Dec 28 05:00  utils\n",
            "-rw-r--r-- 1 root root 74130 Dec 28 05:47 'view?usp=share_link'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4K3I6r3DReB7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}