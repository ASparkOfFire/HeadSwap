{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2KmftFxWxagjDk4RoQ9AH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "491b4dc10ec1441995dbd07bd5e1b775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f43c539eb32c44c6a74f6599c0d8e176",
              "IPY_MODEL_30c866c0f07c4d38a79e90c8996416c3",
              "IPY_MODEL_2053f0ec978e47a4a08899f280ab2f54"
            ],
            "layout": "IPY_MODEL_063c15491d174b0aaa4563dccb677cca"
          }
        },
        "f43c539eb32c44c6a74f6599c0d8e176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50fb2142cd4d4fbfba119b2182dc10ab",
            "placeholder": "​",
            "style": "IPY_MODEL_173dc772ee9d40458a3f8d71cbe6a2c4",
            "value": "100%"
          }
        },
        "30c866c0f07c4d38a79e90c8996416c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02cacc5f34a84bcabc809bc97c6cdc96",
            "max": 46827520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1fe2a0385eb4464ad7633ff551f7c33",
            "value": 46827520
          }
        },
        "2053f0ec978e47a4a08899f280ab2f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_221a6f79a7834aadba8d0f2269f770ea",
            "placeholder": "​",
            "style": "IPY_MODEL_ec553772d4bd44bdb36e36469be30c3c",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 147MB/s]"
          }
        },
        "063c15491d174b0aaa4563dccb677cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50fb2142cd4d4fbfba119b2182dc10ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "173dc772ee9d40458a3f8d71cbe6a2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02cacc5f34a84bcabc809bc97c6cdc96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1fe2a0385eb4464ad7633ff551f7c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "221a6f79a7834aadba8d0f2269f770ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec553772d4bd44bdb36e36469be30c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeslieZhoa/HeadSwap/blob/main/infer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZfYoKXr6rxi",
        "outputId": "280ef530-908e-4815-9983-52e165b9a28f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 28 05:54:26 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P0    31W /  70W |   2038MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download github files"
      ],
      "metadata": {
        "id": "vz21kFuwCvNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/LeslieZhoa/HeadSwap.git\n",
        "%cd HeadSwap/process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5SN8GRf7m6s",
        "outputId": "9307e26c-902c-45b2-d1b2-5c2759ebc9b7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HeadSwap'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 99 (delta 17), reused 76 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (99/99), done.\n",
            "/content/HeadSwap/HeadSwap/process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download model path"
      ],
      "metadata": {
        "id": "bXYkmmu-C9zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! bash download_weight.sh\n",
        "! wget https://raw.githubusercontent.com/sicxu/Deep3DFaceRecon_pytorch/master/BFM/similarity_Lm3D_all.mat -P ../pretrained_models/BFM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux_BOlr58Fe8",
        "outputId": "3c4751ff-23aa-418d-a264-c313cb71af60"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-28 05:55:43--  https://github.com/LeslieZhoa/HeSer.Pytorch/releases/download/v0.0/parsing.pth\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/530152897/e4c87da5-2ba5-43b4-a5d5-24270c4a925c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T055543Z&X-Amz-Expires=300&X-Amz-Signature=9c8bf06abd5148404a992bad91fc5b72f867667354c446f72fa0aea49013c6ba&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=530152897&response-content-disposition=attachment%3B%20filename%3Dparsing.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-28 05:55:43--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/530152897/e4c87da5-2ba5-43b4-a5d5-24270c4a925c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T055543Z&X-Amz-Expires=300&X-Amz-Signature=9c8bf06abd5148404a992bad91fc5b72f867667354c446f72fa0aea49013c6ba&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=530152897&response-content-disposition=attachment%3B%20filename%3Dparsing.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53289463 (51M) [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/parsing.pth.1’\n",
            "\n",
            "parsing.pth.1       100%[===================>]  50.82M   199MB/s    in 0.3s    \n",
            "\n",
            "2022-12-28 05:55:44 (199 MB/s) - ‘../pretrained_models/parsing.pth.1’ saved [53289463/53289463]\n",
            "\n",
            "--2022-12-28 05:55:44--  https://github.com/LeslieZhoa/HeadSwap/releases/download/v0.0/sr_cf.onnx\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/ceed01af-bdaa-4a77-8599-f41da0a9cebf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T055544Z&X-Amz-Expires=300&X-Amz-Signature=93dc3bef411da096feeb2106f59b6b9c8bad53c6990b48ef922de4d75e3b2ce9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=580735966&response-content-disposition=attachment%3B%20filename%3Dsr_cf.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-28 05:55:44--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/ceed01af-bdaa-4a77-8599-f41da0a9cebf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T055544Z&X-Amz-Expires=300&X-Amz-Signature=93dc3bef411da096feeb2106f59b6b9c8bad53c6990b48ef922de4d75e3b2ce9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=580735966&response-content-disposition=attachment%3B%20filename%3Dsr_cf.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 376642743 (359M) [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/sr_cf.onnx.1’\n",
            "\n",
            "sr_cf.onnx.1        100%[===================>] 359.19M   221MB/s    in 1.6s    \n",
            "\n",
            "2022-12-28 05:55:46 (221 MB/s) - ‘../pretrained_models/sr_cf.onnx.1’ saved [376642743/376642743]\n",
            "\n",
            "--2022-12-28 05:55:46--  https://github.com/LeslieZhoa/HeadSwap/releases/download/v0.0/Blender-401-00012900.pth\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/a967bbbb-08bf-440a-86b0-ff59bfea0867?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T055546Z&X-Amz-Expires=300&X-Amz-Signature=bba67668ada86598c74ef5d705c567259ace71fb41f8f1d568ed708f83767af9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=580735966&response-content-disposition=attachment%3B%20filename%3DBlender-401-00012900.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-28 05:55:46--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/a967bbbb-08bf-440a-86b0-ff59bfea0867?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221228T055546Z&X-Amz-Expires=300&X-Amz-Signature=bba67668ada86598c74ef5d705c567259ace71fb41f8f1d568ed708f83767af9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=580735966&response-content-disposition=attachment%3B%20filename%3DBlender-401-00012900.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 788213979 (752M) [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/Blender-401-00012900.pth.1’\n",
            "\n",
            "Blender-401-0001290 100%[===================>] 751.70M   134MB/s    in 5.3s    \n",
            "\n",
            "2022-12-28 05:55:51 (141 MB/s) - ‘../pretrained_models/Blender-401-00012900.pth.1’ saved [788213979/788213979]\n",
            "\n",
            "--2022-12-28 05:55:51--  https://raw.githubusercontent.com/sicxu/Deep3DFaceRecon_pytorch/master/BFM/similarity_Lm3D_all.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 994 [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/BFM/similarity_Lm3D_all.mat.1’\n",
            "\n",
            "similarity_Lm3D_all 100%[===================>]     994  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-28 05:55:52 (55.9 MB/s) - ‘../pretrained_models/BFM/similarity_Lm3D_all.mat.1’ saved [994/994]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup files downloader\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "download_with_pydrive = True #@param {type:\"boolean\"}\n",
        "\n",
        "class Downloader(object):\n",
        "    def __init__(self, use_pydrive):\n",
        "        self.use_pydrive = use_pydrive\n",
        "        current_directory = os.getcwd()\n",
        "        self.save_dir = '../pretrained_models'\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "        if self.use_pydrive:\n",
        "            self.authenticate()\n",
        "\n",
        "    def authenticate(self):\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        self.drive = GoogleDrive(gauth)\n",
        "\n",
        "    def download_file(self, file_id, file_name):\n",
        "        file_dst = f'{self.save_dir}/{file_name}'\n",
        "        if os.path.exists(file_dst):\n",
        "            print(f'{file_name} already exists!')\n",
        "            return\n",
        "        if self.use_pydrive:\n",
        "            downloaded = self.drive.CreateFile({'id':file_id})\n",
        "            downloaded.FetchMetadata(fetch_all=True)\n",
        "            downloaded.GetContentFile(file_dst)\n",
        "        else:\n",
        "            !gdown --id $file_id -O $file_dst\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)"
      ],
      "metadata": {
        "id": "MGEEwCHZCohn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download epoch_20\n",
        "MODEL_PATHS = {\"id\": \"1BlDBB4dLLrlN3cJhVL4nmrd_g6Jx6uP0\", \"name\": \"epoch_20.pth\"}\n",
        "   \n",
        "downloader.download_file(file_id=MODEL_PATHS[\"id\"], file_name=MODEL_PATHS[\"name\"])"
      ],
      "metadata": {
        "id": "gd0BrM1rDO3a"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download PIRender model"
      ],
      "metadata": {
        "id": "n5drU3CIUEY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown https://drive.google.com/uc?id=1-0xOf6g58OmtKtEWJlU3VlnfRqPN9Uq7 -O ../pretrained_models\n",
        "! unzip -x ../pretrained_models/face.zip"
      ],
      "metadata": {
        "id": "hL8N3M_DUD3m",
        "outputId": "295452d4-fc0a-4b97-d57d-04a946cfe020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1-0xOf6g58OmtKtEWJlU3VlnfRqPN9Uq7 \n",
            "\n",
            "unzip:  cannot find or open ../pretrained_models/face.zip, ../pretrained_models/face.zip.zip or ../pretrained_models/face.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## enviroment"
      ],
      "metadata": {
        "id": "8lCGm7VnDc02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch torchvision numpy opencv-python onnxruntime-gpu face-alignment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzfacabV9Bzq",
        "outputId": "87ec6dd1-5200-4f2b-daca-469fc6089a24"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.8/dist-packages (1.13.1)\n",
            "Requirement already satisfied: face-alignment in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (21.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (3.19.6)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime-gpu) (1.7.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from face-alignment) (0.18.3)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from face-alignment) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from face-alignment) (4.64.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from face-alignment) (0.56.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.8/dist-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba->face-alignment) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->face-alignment) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->face-alignment) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->face-alignment) (3.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->onnxruntime-gpu) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (2022.10.10)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face-alignment) (2.8.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.15.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime-gpu) (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypt-WwwU-S3l",
        "outputId": "a4bb08f2-f2da-4e83-d2aa-3579bd06a402"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HeadSwap/HeadSwap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model.AlignModule.generator import FaceGenerator\n",
        "from model.BlendModule.generator import Generator as Decoder\n",
        "from model.AlignModule.config import Params as AlignParams\n",
        "from model.BlendModule.config import Params as BlendParams \n",
        "from model.third.faceParsing.model import BiSeNet\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pdb\n",
        "from process.process_func import Process\n",
        "from process.process_utils import *\n",
        "import os\n",
        "import onnxruntime as ort\n"
      ],
      "metadata": {
        "id": "d1nd1n23-ZET"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Infer(Process):\n",
        "    def __init__(self,align_path,blend_path,parsing_path,params_path,bfm_folder):\n",
        "        Process.__init__(self,params_path,bfm_folder)\n",
        "        align_params = AlignParams()\n",
        "        blend_params = BlendParams()\n",
        "        self.device = 'cpu'\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = 'cuda'\n",
        "      \n",
        "        self.parsing = BiSeNet(n_classes=19).to(self.device)\n",
        "        \n",
        "        self.netG = FaceGenerator(align_params).to(self.device)\n",
        "        self.decoder = Decoder(blend_params).to(self.device)\n",
        "        \n",
        "        self.loadModel(align_path,blend_path,parsing_path)\n",
        "        self.eval_model(self.netG,self.decoder,self.parsing)\n",
        "        \n",
        "\n",
        "        self.ort_session_sr = ort.InferenceSession('./pretrained_models/sr_cf.onnx', providers=['CPUExecutionProvider'])\n",
        "\n",
        "    def run(self,src_img_path_list,tgt_img_path_list,save_base,crop_align=False,cat=False):\n",
        "        os.makedirs(save_base,exist_ok=True)\n",
        "        i = 0\n",
        "        for src_img_path,tgt_img_path in zip(src_img_path_list,tgt_img_path_list):\n",
        "            gen = self.run_single(src_img_path,tgt_img_path,crop_align=crop_align,cat=cat)\n",
        "            img_name = os.path.splitext(os.path.basename(src_img_path))[0]+'-' + \\\n",
        "                        os.path.splitext(os.path.basename(tgt_img_path))[0]+'.png'\n",
        "            cv2.imwrite(os.path.join(save_base,img_name),gen)\n",
        "            print('\\rhave done %04d'%i,end='',flush=True)\n",
        "            i += 1\n",
        "        print()\n",
        "    def run_single(self,src_img_path,tgt_img_path,crop_align=False,cat=False):\n",
        "        \n",
        "        tgt_img = cv2.imread(tgt_img_path)\n",
        "        tgt_align = tgt_img.copy()\n",
        "        \n",
        "        tgt_align,info = self.preprocess_align(tgt_img)\n",
        "        if tgt_align is None:\n",
        "            return None\n",
        "\n",
        "        src_img = cv2.imread(src_img_path)\n",
        "        src_align = src_img\n",
        "        if crop_align:\n",
        "            src_align,_ = self.preprocess_align(src_img,top_scale=0.55)\n",
        "        \n",
        "        src_inp = self.preprocess(src_align)\n",
        "        tgt_inp = self.preprocess(tgt_align)\n",
        "\n",
        "        tgt_params = self.get_params(cv2.resize(tgt_align,(256,256)),\n",
        "                                info['rotated_lmk']/2.0).unsqueeze(0)\n",
        "           \n",
        "        gen = self.forward(src_inp,tgt_inp,tgt_params) \n",
        "\n",
        "        gen = self.postprocess(gen[0])\n",
        "        gen = self.run_sr(gen)\n",
        "        mask = self.mask\n",
        "        final = gen\n",
        "        # gen = color_transfer2(tgt_align,gen)\n",
        "            \n",
        "        RotateMatrix = info['im'][:2]\n",
        "        mask = info['mask'][...,0]\n",
        "       \n",
        "        rotate_gen = cv2.warpAffine(gen, RotateMatrix, (tgt_img.shape[1], tgt_img.shape[0]))\n",
        "        mask = cv2.warpAffine(mask, RotateMatrix, (tgt_img.shape[1], tgt_img.shape[0])) * 1.0\n",
        "\n",
        "        # ori_mask = mask.copy()\n",
        "        kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT,(17, 17))\n",
        "        # mask = cv2.dilate(mask*1.0,kernel2)\n",
        "        mask = cv2.erode(mask*1.0,kernel2)\n",
        "        # mask = cv2.GaussianBlur(mask*255.0, (21, 21), 0) / 255.0\n",
        "        mask = cv2.blur(mask*1.0, (15, 15), 0) / 255.0\n",
        "        mask = np.clip(mask,0,1.0)[:,:,np.newaxis]\n",
        "\n",
        "        # pdb.set_trace()\n",
        "        final = rotate_gen * mask + tgt_img * (1-mask)\n",
        "\n",
        "        if cat:\n",
        "            final = np.concatenate([tgt_img,final],1)\n",
        "            final[-256:,:256] = cv2.resize(src_align,(256,256))\n",
        "\n",
        "        return final\n",
        "    \n",
        "    def forward(self,xs,xt,params):\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # xg = self.netG(F.adaptive_avg_pool2d(xs,256),\n",
        "            #                 F.adaptive_avg_pool2d(xt,256),\n",
        "            #                 params)['fake_image']\n",
        "            xg = F.adaptive_avg_pool2d(self.netG(F.adaptive_avg_pool2d(xs,256),\n",
        "                            F.adaptive_avg_pool2d(xt,256),\n",
        "                            params)['fake_image'],512)\n",
        "           \n",
        "            \n",
        "            M_a = self.parsing(self.preprocess_parsing(xg))\n",
        "           \n",
        "            M_t = self.parsing(self.preprocess_parsing(xt))\n",
        "            \n",
        "            M_a = self.postprocess_parsing(M_a)\n",
        "            M_t = self.postprocess_parsing(M_t)\n",
        "            # xg[M_a.repeat(1,3,1,1)==0] = -0.5\n",
        "            # xg[M_a.repeat(1,3,1,1)==16] = 0.6\n",
        "            xg_gray = TF.rgb_to_grayscale(xg,num_output_channels=1)\n",
        "            fake = self.decoder(xg,xg_gray,xt,M_a,M_t,xt,train=False)\n",
        "            \n",
        "            \n",
        "            gen_mask = self.parsing(self.preprocess_parsing(fake))\n",
        "            gen_mask = self.postprocess_parsing(gen_mask)\n",
        "            gen_mask = gen_mask[0][0].cpu().numpy()\n",
        "            mask_t = M_t[0][0].cpu().numpy()\n",
        "            mask = np.zeros_like(gen_mask)\n",
        "            for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,17,18]:\n",
        "                mask[gen_mask==i] = 1.0\n",
        "                mask[mask_t==i] = 1.0\n",
        "            \n",
        "            self.mask = mask\n",
        "        return fake\n",
        "    \n",
        "    def run_sr(self,input_np):\n",
        "        input_np = cv2.cvtColor(input_np, cv2.COLOR_BGR2RGB)\n",
        "        # prepare data\n",
        "        input_np = input_np.transpose((2,0,1))\n",
        "        input_np = np.array(input_np[np.newaxis, :])\n",
        "        outputs_onnx = self.ort_session_sr.run(None, {'input_image':input_np.astype(np.uint8)})\n",
        "\n",
        "        out_put_onnx = outputs_onnx[0]\n",
        "        outimg = out_put_onnx[0,...].transpose(1,2,0)\n",
        "        outimg = cv2.cvtColor(outimg, cv2.COLOR_BGR2RGB)\n",
        "        return outimg\n",
        "\n",
        "        \n",
        "    def loadModel(self,align_path,blend_path,parsing_path):\n",
        "        ckpt = torch.load(align_path, map_location=lambda storage, loc: storage)\n",
        "        # self.netG.load_state_dict(ckpt['G'])\n",
        "        self.netG.load_state_dict(ckpt['net_G_ema'])\n",
        "\n",
        "        ckpt = torch.load(blend_path, map_location=lambda storage, loc: storage)\n",
        "        self.decoder.load_state_dict(ckpt['G'],strict=False)\n",
        "\n",
        "        self.parsing.load_state_dict(torch.load(parsing_path))\n",
        "\n",
        "    \n",
        "    def eval_model(self,*args):\n",
        "        for arg in args:\n",
        "            arg.eval()\n"
      ],
      "metadata": {
        "id": "0ymbJWEq-edY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Infer(\n",
        "            # 'checkpoint/Aligner/058-00008100.pth',\n",
        "            'pretrained_models/epoch_00190_iteration_000400000_checkpoint.pt',\n",
        "            'pretrained_models/Blender-401-00012900.pth',\n",
        "            'pretrained_models/parsing.pth',\n",
        "            'pretrained_models/epoch_20.pth',\n",
        "            'pretrained_models/BFM')\n",
        "\n",
        "# find_path = lambda x: [os.path.join(x,f) for f in os.listdir(x)]\n",
        "# img_paths = find_path('../HeadSwap/test_img')[::-1]\n",
        "\n",
        "src_paths = ['./assets/5.jpg']\n",
        "tgt_paths = ['assets/fe54875c-2cf0-4147-b08a-80552a9f46be.jpg']\n",
        "\n",
        "model.run(src_paths,tgt_paths,save_base='res-1125',crop_align=True,cat=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445,
          "referenced_widgets": [
            "491b4dc10ec1441995dbd07bd5e1b775",
            "f43c539eb32c44c6a74f6599c0d8e176",
            "30c866c0f07c4d38a79e90c8996416c3",
            "2053f0ec978e47a4a08899f280ab2f54",
            "063c15491d174b0aaa4563dccb677cca",
            "50fb2142cd4d4fbfba119b2182dc10ab",
            "173dc772ee9d40458a3f8d71cbe6a2c4",
            "02cacc5f34a84bcabc809bc97c6cdc96",
            "b1fe2a0385eb4464ad7633ff551f7c33",
            "221a6f79a7834aadba8d0f2269f770ea",
            "ec553772d4bd44bdb36e36469be30c3c"
          ]
        },
        "id": "kkagbZIP_ZAQ",
        "outputId": "189e372d-32c1-4149-b8b4-a89744bddd42"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "491b4dc10ec1441995dbd07bd5e1b775"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6349e095f330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = Infer(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0;31m# 'checkpoint/Aligner/058-00008100.pth',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0;34m'pretrained_models/epoch_00190_iteration_000400000_checkpoint.pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;34m'pretrained_models/Blender-401-00012900.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m'pretrained_models/parsing.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-267e6b1e17d7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, align_path, blend_path, parsing_path, params_path, bfm_folder)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblend_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malign_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblend_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparsing_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-267e6b1e17d7>\u001b[0m in \u001b[0;36mloadModel\u001b[0;34m(self, align_path, blend_path, parsing_path)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malign_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblend_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparsing_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malign_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;31m# self.netG.load_state_dict(ckpt['G'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'net_G_ema'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pretrained_models/epoch_00190_iteration_000400000_checkpoint.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l pretrained_models/BFM"
      ],
      "metadata": {
        "id": "eWLI6T-9_d_C",
        "outputId": "1544e782-a620-4ad6-f3a2-b4d4647e0372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 140\n",
            "-rw-r--r-- 1 root root 140235 Dec 28 04:58 similarity_Lm3D_all.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWPDTpQ_BkcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://drive.google.com/drive/folders/1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP -P pretrained_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CHS6gypCVLe",
        "outputId": "ce4ded92-a33c-46e4-c6f6-98c61f7f9c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-28 05:07:24--  https://drive.google.com/drive/folders/1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.194.100, 173.194.194.139, 173.194.194.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.194.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘pretrained_models/1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP’\n",
            "\n",
            "\r          1liaIxn9s     [<=>                 ]       0  --.-KB/s               \r1liaIxn9smpudjjqMaW     [ <=>                ] 231.83K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-12-28 05:07:24 (2.84 MB/s) - ‘pretrained_models/1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP’ saved [237398]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l pretrained_models/"
      ],
      "metadata": {
        "id": "SDhgLURACaiT",
        "outputId": "9b4e73d8-165e-4a90-bb62-3ef0d954de79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1471940\n",
            "-rw-r--r-- 1 root root    237398 Dec 28 05:07 1liaIxn9smpudjjqMaWWRpP0mXRW_qRPP\n",
            "drwxr-xr-x 2 root root      4096 Dec 28 04:58 BFM\n",
            "-rw-r--r-- 1 root root 788213979 Dec 21 14:10 Blender-401-00012900.pth\n",
            "-rw-r--r-- 1 root root 288860037 Dec 28 05:50 epoch_20.pth\n",
            "-rw-r--r-- 1 root root  53289463 Aug 30 08:51 parsing.pth\n",
            "-rw-r--r-- 1 root root 376642743 Dec 21 13:19 sr_cf.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l"
      ],
      "metadata": {
        "id": "QzUbX9ZCIO4R",
        "outputId": "8947f7a9-a34d-4801-9d9a-b6cf67678b96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 276\n",
            "drwxr-xr-x 2 root root  4096 Dec 28 04:56  assets\n",
            "drwxr-xr-x 3 root root  4096 Dec 28 05:00  dataloader\n",
            "-rw-r--r-- 1 root root 74124 Dec 28 05:49  epoch_20.pth\n",
            "-rw-r--r-- 1 root root  7005 Dec 28 04:56  inference.py\n",
            "-rw-r--r-- 1 root root 75762 Dec 28 04:56  infer.ipynb\n",
            "-rw-r--r-- 1 root root  1067 Dec 28 04:56  LICENSE\n",
            "drwxr-xr-x 5 root root  4096 Dec 28 04:56  model\n",
            "drwxr-xr-x 3 root root  4096 Dec 28 05:50  pretrained_models\n",
            "drwxr-xr-x 3 root root  4096 Dec 28 05:00  process\n",
            "-rw-r--r-- 1 root root  2883 Dec 28 04:56  ReadMe.md\n",
            "drwxr-xr-x 2 root root  4096 Dec 28 04:56  trainer\n",
            "-rw-r--r-- 1 root root  3702 Dec 28 04:56  train.py\n",
            "drwxr-xr-x 3 root root  4096 Dec 28 05:00  utils\n",
            "-rw-r--r-- 1 root root 74130 Dec 28 05:47 'view?usp=share_link'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4K3I6r3DReB7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}